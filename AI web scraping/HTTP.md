![[Pasted image 20250208223340.png]]

#### communication protocol that allows exchange of information b/w a client and a server
![[Pasted image 20250208223827.png]]

A hypertext - text with links embedded that have more information which a user can get.

![[Pasted image 20250208223924.png]]

![[Pasted image 20250208224134.png]]

# State less protocol.
![[Pasted image 20250208225412.png]]

A **stateless protocol** is a type of communication protocol in which each request from a client to a server is treated as an independent transaction, with no memory of previous requests. This means that the server does not retain any session or user data between requests.

#### but sites do remember us when we move from page to page.
### this is where browser cookies comes in.
![[Pasted image 20250215010024.png]]

#### cookies are generated by server and stored on the client side browser.
the client browser gives off responses to the server with data or cookies
so cookies go to the server side with every request that is made by client.

server then checks the data and sees if the user/client can do a certain task or not.(like logging in and stuff as it is stored inside cookie , the username and stuff)

this is how internet or sites remembers us.

## user agents
![[Pasted image 20250215010538.png]]

##### a user agent is a software that is used to access web on behalf of the user.
it can be a browser , a web crawler ,a bot, a script
user agent is the client in the HTTP communication it initiates request and then gets a response back from the server

# http verbs

![[Pasted image 20250215011115.png]]

HTTP (Hypertext Transfer Protocol) verbs, also known as HTTP methods, are used to indicate the desired action to be performed on a resource identified by a URL. Here are the most common HTTP verbs:

1. **GET**: Requests data from a specified resource. It should only retrieve data and not modify it.
    
2. **POST**: Submits data to be processed to a specified resource. Often used to create new resources or submit forms.
    
3. **PUT**: Updates a specified resource with the provided data. It replaces the entire resource with the new data.
    
4. **DELETE**: Deletes a specified resource.
    
5. **PATCH**: Partially updates a specified resource with the provided data. Unlike PUT, it only modifies the fields that are provided.

#### web scraping mainly uses GET as it is basically taking data from the web sites or stuff so yes.

### a server is not obligated to perform any request given by a client as there can be a request that a certain client isnt permitted to do so
like entering a username and entering a pass that isnt correct 
so going to that account isnt feasable and server side will not permit this request to be made.

# status codes (3 digit number)

![[Pasted image 20250215011643.png]]

##### HTTP status codes are standardized codes returned by a server in response to a client's request. They indicate whether the request was successful, encountered an error, or requires further action.
like in example he showed when giving request to connect to google.com 
the response had 200 as the status code which means - OK (request processed).

1. ![[Pasted image 20250215011814.png]]
### informational status codes (quite rare in practice)

2. ![[Pasted image 20250215012012.png]]
### success status codes
3.  ![[Pasted image 20250215012110.png]]
### redirection resources 
4. ![[Pasted image 20250215012157.png]]
### client errors (famous one 404 the resource wasnt found )
5.![[Pasted image 20250215012403.png]]
### server errors status codes
##### an example
![[Pasted image 20250215012520.png]]

here we are sending a request to GET the resource that is google.com
which in response we get 

![[Pasted image 20250215012602.png]]
200 OK as the status code.

But when we change the verb to delete and then try to delete google.com (lol).
![[Pasted image 20250215012711.png]]
then we are met with the status code 405 that is a client error method not allowed 
generally means that this request cant be done and permitted by the said client which requested it.
![[Pasted image 20250215012810.png]]
# headers

HTTP headers are key-value pairs sent between a client (e.g., a browser) and a server during an HTTP request or response. They provide additional information about the request or response, such as metadata, authentication details, caching behavior, and more.

![[Pasted image 20250215013006.png]]
##### as you can see these are some headers that we got when accessing google.com
these headers are from the server side and all of em might seem very agdam tigdam but some are easy to understand like "date".

also giving the cookie which server sends to the browser and when browser request the same resource (in this case google.com) we create a memory in the servers mind ad get things done quickly.

1. **Response Headers**:
    
    - Sent by the server to the client as part of an HTTP response.
        
    - Provide information about the server, the response, and how the client should handle it.
        
    - Examples:
        
        - `Content-Type`: Specifies the media type of the response (e.g., `application/json`).
            
        - `Set-Cookie`: Sends cookies from the server to the client for future requests.
            
        - `Cache-Control`: Directs caching behavior (e.g., `max-age=3600`).
            
        - `Location`: Used in redirects to specify the new URL.

#### (the one photo we saw above is an example of response header).
2. **Request Headers**:
    
    - Sent by the client to the server as part of an HTTP request.
        
    - Provide information about the client, the requested resource, and how the response should be formatted.
        
    - Examples:
        
        - `User-Agent`: Identifies the client (e.g., browser or device) making the request.
            
        - `Accept`: Specifies the media types (e.g., JSON, HTML) the client can handle.
            
        - `Authorization`: Contains credentials for authentication (e.g., Bearer tokens).
            
        - `Cookie`: Sends cookies stored on the client to the server.

![[Pasted image 20250215013351.png]]

here as u can see we are giving a request header for es-Mx (basically means spanish lang dedo page mein as accept-language header is used)

then client/browser renders the page like this 
![[Pasted image 20250215013505.png]]

![[Pasted image 20250215013633.png]]

quite imp in scraping.
used in our way as to represent ourselves as some "google crawler bot" that can scrape as many servers are designed in a way to decline scrape requests.

![[Pasted image 20250215231937.png]]

# proxies
![[Pasted image 20250215232720.png]]

A **proxy** is an intermediary server that sits between a client (such as your browser or a web crawler) and the internet. It forwards requests to websites on your behalf, which can help with privacy, security, or bypassing restrictions.

![[Pasted image 20250215232956.png]]

##### CACHING PROXY EXAMPLE:
stores copy of the responses locally 
if some request is made a second time and the cache proxy server has the response for it then it sends back that response

if it doesnt then it proceeds to the server.

![[Pasted image 20250215233357.png]]

##### LOAD BALANCER PROXY:
just distributes the incoming load to many servers

![[Pasted image 20250215233544.png]]

bot like behavior is escaped through this (sending 10k requests in seconds and by the same ip). 
by using proxies 
